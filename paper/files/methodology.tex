\section{Methodology}

We focus on a learning based approach. Our overall approach is shown in Fig.~\ref{fig:architecture}.


\subsection{Bayes Filter for SLAM}

We assume that our system is Markovian with the state vector $\state_t := [\map^\top,
\pose_t^\top, \act_{1,t}^\top, \tgt_1^\top, \dots \act_{N,t}^\top, \tgt_N^\top]^\top$, that includes map, robot
pose and the target poses.
However, only activation state $\act_{i,t}$, the lidar observation $\lidar_t$ and the signal $\rssi_t$ is observable.
To estimate the state, we use a typical Simultaneous Localization and
Mapping (SLAM) pipeline that uses Bayes Filter to update the distribution over the
state,
%
\begin{align}
  \bel_0(\state_0) &:= p(\state_0)
  \\
\bel_t(\state_{t}) &:= p(\state_t|\lidar_{1:t}, \rssi_{1:t}, \act_{1:N,1:t}, \ctrl_{1:t-1})
  \\
  \bel_t(\state_{t}) &\propto \E_{\state_{t-1}} \left[p(\lidar_{t}|\state_{t})p(\rssi_{t}| \state_{t})p(\state_{t}|\state_{t-1}, \ctrl_{t-1}) \right]
                       \label{eq:bayes-filter}
\end{align}%
% 

Here $p(\lidar_t|\state_{t})$, $p(\rssi_t|\state_t)$  and
$p(\state_t|\state_{t-1}, \ctrl_{t-1})$ are the lidar observation model
$\LidarModel$, signal $\RSSIModel$ and the state transition model.
The observation models are known,
%
\begin{align}
  \lidar_t | \state_t &\sim \N(\LidarModel(\pose_t, \map), \lCov)
  \\
  \rssi_t | \state_t &\sim \N\left(\sum_{i=1}^N \act_{i,t}\RSSIModel(\pose_t, \tgt_i, \map), \rCov\right).
\end{align}%
% 

The transition model for robot pose and the source activations is known,
%
\begin{align}
p(\state_t|\state_{t-1}, \ctrl_{t-1}) &= p(\pose_t|\pose_{t-1}, \ctrl_{t-1}, \map)\prod_{i=1}^N p(\act_{i,t}|\act_{i,t-1}, \pose_{t-1}, \tgt_i, \map)
  \\
 \pose_t|\pose_{t-1}, \ctrl_{t-1}, \map &\sim \N\left(\dyn(\pose_{t-1}, \ctrl_{t-1}, \map), \pCov \right)
  \\
  p(\act_{i,t}|\act_{i,t-1}, &\pose_{t-1}, \tgt_i, \map) \nonumber \\
                              &= \ind[\act_{i,t} = \max\{\AlgObjDet(\pose_{t-1}, \tgt_i, \map), \act_{i,t-1} \}],
\end{align}%
%
where $\act_{i,t}$ is observed deterministically.

As a result, our SLAM pipeline gives us beliefs over map $\bel_t(\map)$, robot
pose $\bel_t(\pose_t)$ and signal source locations $\bel_t(\tgt_i)$. We
represent $\bel_t(\map)$ as occupancy grid map $\bel_t(\map) \in [0,1]^{w \times
  h}$,
and robot pose and source locations as Gaussian distributions $\bel_t(\pose_t)
\sim \N(\mpose_t, \SPose_t)$ and $\bel_t(\tgt_i) \sim \N(\mtgt_{i,t}, \STgt_{i,t})$.


\subsection{Map prediction using image inpainting}

Having computed the distributions over map, robot pose and signal sources, we
want to compute the best action that leads to largest gain in information about
the signal sources.
To evaluate the cost of proposed actions, we need to know the map.
At any timestep large parts of the map may still be unknown.
We know that many environments, like urban indoor environments, exhibit
structured patterns forming priors over the maps.
To exploit these priors over certain environment types, we formulate the
map-prediction problem as image in-painting problem.
%
\begin{problem}[Map prediction as Image inpainting]
Given a map belief $\bel(\map) \in [0, 1]^{w \times h}$ and a mask $\mask \in
\{0, 1\}^{w \times h}$ such that the pixels $(i,j)$ where $\mask[i, j] = 0$ the
$\bel(\map[i, j])$ is assumed to be known while all other pixels are considered
unknown and need to be estimated. We assume a dataset of i.i.d. sampled maps and
masks $\Data = \{\bel_i(\map_i), \mask_i\}_{i=1}^d$ is given. We train a
parameteric estimator of the desired output $\bel'(\map)$ given the masked map $\bel(\map[\mask])$,
%
\begin{align}
  \Theta &= \arg\max_{\Theta} \sum_{i \in \Data} \log p (\bel_i(\map_i)| \bel_i(\map_i[\mask_i]); \Theta),
\end{align}%
% 
where $\bel_i(\map_i[\mask_i])$ denotes a masked map where only the pixels
$bel_i(\map_i[k,l])$ where $\mask_i[k,l] = 0$ are retained and the rest are set
to 0.
\end{problem}

A lot of work has been done image in-painting domain, we use a well written,
easy to run library called DeepFill~\cite{yu2018DeepFill} for map-prediction.
We briefly explain the DeepFill algorithm for sake of completeness.

\subsubsection{Image inpainting with DeepFill}

The architecture diagram for DeepFill is shown in Fig~\ref{fig:deepfill}.
DeepFill algorithm is based on Generative Adversarial Networks
(GAN)~\cite{goodfellow2014GAN} which are models to generate realistic images.
The main idea for GAN is a pair of adversarial networks, a Generator $G(b;
\theta_g)$ and a discriminator $D(a; \theta_d)$.
Given samples of real images $a \sim p_{\text{data}}(a)$, and images generated by
generator $G(a; \theta_g)$, we want to train the discriminator $D(a; \theta_d)$
to distinguish between real and fake images. Thus the GANs are trained with the
following loss function~\cite{goodfellow2014GAN},
%
\begin{align}
  \theta^*_g, \theta^*_d = \min_{\theta_g} \max_{\theta_d} \E_{a \sim p_{\text{data}}(a)}[\log D(a)]
  + \nonumber \\  \E_{b \sim p_z(b)} [\log(1-D(G(b))]
\end{align}%
% 

While the detailed architecture of DeepFill algorithm is beyond the scope of this
paper, we mention the main idea of \textit{Gated convolutions}. Gated convolutions learn a
learned gate from the mask that gets applied to the regular feature convolutions
from the image~\cite{yu2018DeepFill},

%
\begin{align}
  \textit{Gating}_{y,x} &=  W_g \circledast I 
  \\
  \textit{Feature}_{y,x} &=  W_f \circledast I 
  \\
  O_{y,x} &= \phi(\textit{Feature}_{y,x}) \otimes \sigma(\textit{Gating}_{y,x}),
\end{align}%
% 
where $\circledast$ is the convolution operator, $\sigma$ is sigmoid function,
$\phi$ is any non-linear activation and $\otimes$ is element-wise product.


% 
\subsection{Active exploration in partially observable  environments}

We use ideas from information adaptive sampling~\cite{choudhury2017adaptive},
to compute the optimal trajectory for maximum information gain. However, unlike
Choudhury~et~al.~\cite{choudhury2017adaptive} we use a model-based learning
algorithm instead of model-free imitation-learning.
Specifically, having a model for predicting missing parts of the map.
We use the predicted map to convert the \texttt{Unkown-Map} information
gathering problem into a \texttt{Known-Map} information gathering problem.